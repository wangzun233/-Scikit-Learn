# 概率基础

## 概率定义：

一件事情发生的可能性，用在算法中，**样本的数量越大，得到的概率越准**

# 联合概率，条件概率与相互独立

- 联合概率：包含多个条件，且所有条件同时成立的概率
  - 记作：P(A,B)
  - P(程序员，超重)，P(程序员，超重|喜欢)
- 条件概率：就是事件A在另一个事件B已经发生的情况下发生的概率
  - 记作：P(A|B)
  - P(程序员|喜欢)，P(程序员，超重|喜欢)
- 相互独立：如果P(A,B) = P(A)P(B)，则称事件A与事件B相互独立

![](http://img.wangzun233.top/%E9%BB%91%E9%A9%AC%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A020.png)

# 朴素+贝叶斯公式 = 朴树贝叶斯公式

## 贝叶斯公式

![](http://img.wangzun233.top/%E9%BB%91%E9%A9%AC%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A021.png)

![](http://img.wangzun233.top/%E9%BB%91%E9%A9%AC%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A007_3.png)

## 什么是朴素

**假设特征和特征之间是相互独立的**

## 拉普拉斯平滑系数

防止概率为零

![](http://img.wangzun233.top/%E9%BB%91%E9%A9%AC%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A007_4.png)

# API:

![](http://img.wangzun233.top/%E9%BB%91%E9%A9%AC%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A007_5.png)

# 应用

文本分类，单词作为特征

## 案例:20类新闻分类

1. 获取数据
2. 划分数据集
3. 特征工程：文本特征抽取
4. 朴素贝叶斯预估器流程
5. 模型评估

```python
from sklearn.datasets import fetch_20newsgroups
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
def nb_news():
    """
    用朴素贝叶斯算法对新闻进行分类
    :return:
    """
    # 1）获取数据
    news = fetch_20newsgroups(subset="all")

    # 2）划分数据集
    x_train, x_test, y_train, y_test = train_test_split(news.data, news.target)

    # 3）特征工程：文本特征抽取-tfidf
    transfer = TfidfVectorizer()
    x_train = transfer.fit_transform(x_train)
    x_test = transfer.transform(x_test)

    # 4）朴素贝叶斯算法预估器流程
    estimator = MultinomialNB()
    estimator.fit(x_train, y_train)

    # 5）模型评估
    # 方法1：直接比对真实值和预测值
    y_predict = estimator.predict(x_test)
    print("y_predict:\n", y_predict)
    print("直接比对真实值和预测值:\n", y_test == y_predict)

    # 方法2：计算准确率
    score = estimator.score(x_test, y_test)
    print("准确率为：\n", score)

    return None
if __name__ == '__main__':
    nb_news()


```



# 总结

- 优点：
  - 有稳定的分类效率
  - 对缺失数据不敏感，算法比较简单，常用于文本分类
  - 分类准确度高，速度快
- 缺点：
  - 由于假定数据相互独立，数据关联事不太好