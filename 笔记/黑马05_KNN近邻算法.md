## 什么是k-近邻算法

核心思想：**根据你的“邻居”来推断出你的类别**

定义：如果一个样本特征空间中的K个最相似（既特征空间中最近邻）的样本中的大多数属于摸一个类别，则该样本也属于这个类别

距离公式（欧式距离）：

![](http://img.wangzun233.top/%E9%BB%91%E9%A9%AC%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A016.png)

还有：曼哈顿距离 = 绝对值距离，明科夫斯基距离



## 处理

**k值取得过小，容易受到异常点的影响**

**k值取得过大，会受到样本不均衡的影响**

**无量纲化：标准化** 

## API

![](http://img.wangzun233.top/%E9%BB%91%E9%A9%AC%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A017.png)

## 优点

- 简单，易于理解，易于实现，无须训练

## 缺点

- 必须指定k值 k值选择不当则分类精度不能保证
- 懒惰算法，对测试样本分类时的计算量大，内存开销大

## 应用

- 小数据场景，几千~几万的样本

## 案例1：鸢尾花种类预测

1. 获取数据
2. 数据集划分
3. 特征工程
   1. 标准化
4. KNN预估器流程
5. 模型评估

## 案例2：预测签到位置

流程分析：

1. 获取数据
2. 数据处理
   1. 特征值：x
   2. 特征值：y
   3. 缩小数据范围
   4. 过滤签到次数少的点
   5. 数据集划分
3. 特征工程：标准化
4. KNN算法预估流程
5. 模型选择与调优
6. 模型评估0